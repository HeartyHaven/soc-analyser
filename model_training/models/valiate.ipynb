{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def generation_init_weights(module):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1\n",
    "                                    or classname.find('Linear') != -1):\n",
    "            \n",
    "            if hasattr(m, 'weight') and m.weight is not None:\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    module.apply(init_func)\n",
    "\n",
    "def load_state_dict(module, state_dict, strict=False, logger=None):\n",
    "    unexpected_keys = []\n",
    "    all_missing_keys = []\n",
    "    err_msg = []\n",
    "\n",
    "    metadata = getattr(state_dict, '_metadata', None)\n",
    "    state_dict = state_dict.copy()\n",
    "    if metadata is not None:\n",
    "        state_dict._metadata = metadata\n",
    "\n",
    "    def load(module, prefix=''):\n",
    "        local_metadata = {} if metadata is None else metadata.get(\n",
    "            prefix[:-1], {})\n",
    "        module._load_from_state_dict(state_dict, prefix, local_metadata, True,\n",
    "                                     all_missing_keys, unexpected_keys,\n",
    "                                     err_msg)\n",
    "        for name, child in module._modules.items():\n",
    "            if child is not None:\n",
    "                load(child, prefix + name + '.')\n",
    "\n",
    "    load(module)\n",
    "    load = None\n",
    "\n",
    "    missing_keys = [\n",
    "        key for key in all_missing_keys if 'num_batches_tracked' not in key\n",
    "    ]\n",
    "\n",
    "    if unexpected_keys:\n",
    "        err_msg.append('unexpected key in source '\n",
    "                       f'state_dict: {\", \".join(unexpected_keys)}\\n')\n",
    "    if missing_keys:\n",
    "        err_msg.append(\n",
    "            f'missing keys in source state_dict: {\", \".join(missing_keys)}\\n')\n",
    "\n",
    "    if len(err_msg) > 0:\n",
    "        err_msg.insert(\n",
    "            0, 'The model and loaded state dict do not match exactly\\n')\n",
    "        err_msg = '\\n'.join(err_msg)\n",
    "        if strict:\n",
    "            raise RuntimeError(err_msg)\n",
    "        elif logger is not None:\n",
    "            logger.warning(err_msg)\n",
    "        else:\n",
    "            print(err_msg)\n",
    "    return missing_keys\n",
    "\n",
    "class conv(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "        super(conv, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class upconv(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(upconv, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                nn.ConvTranspose2d(dim_in, dim_out, 4, 2, 1),\n",
    "                nn.InstanceNorm2d(dim_out, affine=True),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class out_conv(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size=1, stride=1, padding=0, bias=False):\n",
    "        super(out_conv, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim=out_dim\n",
    "        self.scale_img_2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.scale_img_3 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.scale_img_4 = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "        self.c1_1 = conv(self.in_dim, 8)  \n",
    "        self.c1_2 = conv(8,8)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.c2_1 = conv(self.in_dim, 16)\n",
    "        self.c2_2 = conv(16+8, 16)\n",
    "        self.c2_3 = conv(16, 16)        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.c3_1 = conv(self.in_dim, 32)\n",
    "        self.c3_2 = conv(32+16, 32)\n",
    "        self.c3_3 = conv(32, 32)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.c4_1 = conv(self.in_dim, out_dim)\n",
    "        self.c4_2 = conv(out_dim+32, out_dim)\n",
    "        self.c4_3 = conv(out_dim, out_dim)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def init_weights(self):\n",
    "        generation_init_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        scale_img_2 = self.scale_img_2(input)#1/2\n",
    "        scale_img_3 = self.scale_img_3(scale_img_2)#1/4\n",
    "        scale_img_4 = self.scale_img_4(scale_img_3)#1/8\n",
    "\n",
    "        c1=self.c1_1(input)#1,8\n",
    "        print('stage1.1:',c1.shape)\n",
    "        c1=self.c1_2(c1)\n",
    "        print('stage1.2:',c1.shape)\n",
    "        p1=self.pool1(c1)#1/2\n",
    "        print('stage1.3:',p1.shape)\n",
    "        \n",
    "        i2=self.c2_1(scale_img_2)#1/2,16\n",
    "        print('stage2.1:',i2.shape)\n",
    "        i2= torch.cat((p1,i2),dim=1)\n",
    "        print('stage2.2:',i2.shape)\n",
    "        c2=self.c2_2(i2)\n",
    "        print('stage2.3:',c2.shape)\n",
    "        c2=self.c2_3(c2)\n",
    "        print('stage2.4:',c2.shape)\n",
    "        p2=self.pool2(c2)#1/4\n",
    "        print('stage2.5:',p2.shape)\n",
    "        \n",
    "        i3=self.c3_1(scale_img_3)#1/4,32\n",
    "        print('stage3.1:',i3.shape)\n",
    "        i3= torch.cat((p2,i3),dim=1)\n",
    "        print('stage3.2:',i3.shape)\n",
    "        c3=self.c3_2(i3)\n",
    "        print('stage3.3:',c3.shape)\n",
    "        c3=self.c3_3(c3)\n",
    "        print('stage3.4:',c3.shape)\n",
    "        p3=self.pool3(c3)#1/8\n",
    "        print('stage3.5:',p3.shape)\n",
    "        \n",
    "        i4=self.c4_1(scale_img_4)#1/8,64\n",
    "        print('stage4.1:',i4.shape)\n",
    "        i4= torch.cat((p3,i4),dim=1)\n",
    "        print('stage4.2:',i4.shape)\n",
    "        c4=self.c4_2(i4)\n",
    "        print('stage4.3:',c4.shape)\n",
    "        c4=self.c4_3(c4)  \n",
    "        print('stage4.4:',c4.shape)\n",
    "        p4=self.pool4(c4)#1/16,64\n",
    "        \n",
    "        return p1,p2,p3,p4 \n",
    " \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, out_dim=2, in_dim=64):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.upc1 = upconv(64, 32)#1/8--1/4\n",
    "        self.c1_1= conv(32+32,32)\n",
    "        self.c1_2=conv(32,32)\n",
    "\n",
    "        self.upc2 = upconv(32, 16)#1/4--1/2\n",
    "        self.c2_1= conv(16+16,16)\n",
    "        self.c2_2=conv(16,16)\n",
    "        \n",
    "        self.upc3 = upconv(16, 8)#1/2--1\n",
    "        self.c3_1= conv(8+8,8)\n",
    "        self.c3_2=conv(8,8)       \n",
    "        \n",
    "        self.sc1=nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
    "        self.sc2=nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        self.sc3=nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.outlayer1=out_conv(64,2)\n",
    "        self.outlayer2=out_conv(32,2)\n",
    "        self.outlayer3=out_conv(16,2)\n",
    "\n",
    "    def init_weights(self):\n",
    "        generation_init_weights(self)\n",
    "\n",
    "    def forward(self, vals):\n",
    "        print('##DECODER')\n",
    "        u1= self.upc1(vals[3])\n",
    "        print('stage1.1:',u1.shape)\n",
    "        \n",
    "        u1= torch.cat((u1,vals[2]),dim=1)\n",
    "        print('stage1.2:',u1.shape)\n",
    "        c1= self.c1_1(u1)\n",
    "        print('stage1.3:',c1.shape)\n",
    "        c1= self.c1_2(c1)\n",
    "        print('stage1.4:',c1.shape)\n",
    "\n",
    "        u2= self.upc2(vals[2])\n",
    "        print('stage2.1:',u2.shape)\n",
    "        u2= torch.cat((u2,vals[1]),dim=1)\n",
    "        print('stage2.2:',u2.shape)\n",
    "        c2= self.c2_1(u2)\n",
    "        print('stage2.3:',c2.shape)\n",
    "        c2= self.c2_2(c2)\n",
    "        print('stage2.4:',c2.shape)\n",
    "        \n",
    "        u3= self.upc3(vals[1])\n",
    "        print('stage3.1:',u3.shape)\n",
    "        u3= torch.cat((u3,vals[0]),dim=1)\n",
    "        print('stage3.2:',u3.shape)\n",
    "        c3= self.c3_1(u3)\n",
    "        print('stage3.3:',c3.shape)\n",
    "        c3= self.c3_2(c3)\n",
    "        print('stage3.4:',c3.shape)\n",
    "        \n",
    "        out3=self.sc3(u3)\n",
    "        print('stage4.1:',out3.shape)\n",
    "        out3=self.outlayer3(out3)\n",
    "        print('stage4.1:',out3.shape)\n",
    "        out2=self.sc2(u2)\n",
    "        print('stage4.2:',out2.shape)\n",
    "        out2=self.outlayer2(out2)\n",
    "        print('stage4.2:',out2.shape)\n",
    "        out1=self.sc1(u1)\n",
    "        print('stage4.3:',out1.shape)\n",
    "        out1=self.outlayer1(out1)\n",
    "        print('stage4.3:',out1.shape)\n",
    "        \n",
    "        out=torch.mean(torch.stack([out1,out2,out3],dim=1),1,False)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=3,\n",
    "                 out_channels=2,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(in_dim=3)\n",
    "        self.decoder = Decoder(out_dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape[1])\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def init_weights(self, pretrained=None, pretrained_transfer=None, strict=False, **kwargs):\n",
    "        if isinstance(pretrained, str):\n",
    "            new_dict = OrderedDict()\n",
    "            weight = torch.load(pretrained, map_location='cpu')['state_dict']\n",
    "            for k in weight.keys():\n",
    "                new_dict[k] = weight[k]\n",
    "            load_state_dict(self, new_dict, strict=strict, logger=None)\n",
    "            print('Load state dict form {}'.format(pretrained))\n",
    "        elif pretrained is None:\n",
    "            generation_init_weights(self)\n",
    "        else:\n",
    "            raise TypeError(\"'pretrained' must be a str or None. \"\n",
    "                            f'But received {type(pretrained)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面验证模型的正确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1.1: torch.Size([1, 8, 32, 32])\n",
      "stage1.2: torch.Size([1, 8, 32, 32])\n",
      "stage1.3: torch.Size([1, 8, 16, 16])\n",
      "stage2.1: torch.Size([1, 16, 16, 16])\n",
      "stage2.2: torch.Size([1, 24, 16, 16])\n",
      "stage2.3: torch.Size([1, 16, 16, 16])\n",
      "stage2.4: torch.Size([1, 16, 16, 16])\n",
      "stage2.5: torch.Size([1, 16, 8, 8])\n",
      "stage3.1: torch.Size([1, 32, 8, 8])\n",
      "stage3.2: torch.Size([1, 48, 8, 8])\n",
      "stage3.3: torch.Size([1, 32, 8, 8])\n",
      "stage3.4: torch.Size([1, 32, 8, 8])\n",
      "stage3.5: torch.Size([1, 32, 4, 4])\n",
      "stage4.1: torch.Size([1, 64, 4, 4])\n",
      "stage4.2: torch.Size([1, 96, 4, 4])\n",
      "stage4.3: torch.Size([1, 64, 4, 4])\n",
      "stage4.4: torch.Size([1, 64, 4, 4])\n",
      "##DECODER\n",
      "stage1.1: torch.Size([1, 32, 4, 4])\n",
      "stage1.2: torch.Size([1, 64, 4, 4])\n",
      "stage1.3: torch.Size([1, 32, 4, 4])\n",
      "stage1.4: torch.Size([1, 32, 4, 4])\n",
      "stage2.1: torch.Size([1, 16, 8, 8])\n",
      "stage2.2: torch.Size([1, 32, 8, 8])\n",
      "stage2.3: torch.Size([1, 16, 8, 8])\n",
      "stage2.4: torch.Size([1, 16, 8, 8])\n",
      "stage3.1: torch.Size([1, 8, 16, 16])\n",
      "stage3.2: torch.Size([1, 16, 16, 16])\n",
      "stage3.3: torch.Size([1, 8, 16, 16])\n",
      "stage3.4: torch.Size([1, 8, 16, 16])\n",
      "stage4.1: torch.Size([1, 16, 32, 32])\n",
      "stage4.1: torch.Size([1, 2, 32, 32])\n",
      "stage4.2: torch.Size([1, 32, 32, 32])\n",
      "stage4.2: torch.Size([1, 2, 32, 32])\n",
      "stage4.3: torch.Size([1, 64, 32, 32])\n",
      "stage4.3: torch.Size([1, 2, 32, 32])\n",
      "torch.Size([1, 2, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 3, 32, 32)\n",
    "model=MNet()\n",
    "pred=model(input_tensor)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
